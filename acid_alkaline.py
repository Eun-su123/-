import streamlit as st
import time
import os
import json
from PIL import Image, ImageDraw
import google.generativeai as genai

# --- ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ ---
def create_images_if_needed():
    """í•„ìš”í•œ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    image_dir = "images"
    os.makedirs(image_dir, exist_ok=True)

    # ì´ë¯¸ì§€ ì •ë³´: íŒŒì¼ëª…, ë°°ê²½ìƒ‰, í…ìŠ¤íŠ¸, í…ìŠ¤íŠ¸ ìƒ‰
    images_to_create = {
        "litmus_red.png": ("#FF5733", "ë¶‰ê²Œ ë³€í•¨", "white"),
        "litmus_blue.png": ("#335BFF", "í‘¸ë¥´ê²Œ ë³€í•¨", "white"),
        "phenol_colorless.png": ("#E0E0E0", "ë³€í™” ì—†ìŒ", "black"),
        "phenol_red.png": ("#FF33A1", "ë¶‰ê²Œ ë³€í•¨", "white"),
    }

    for filename, (color, text, text_color) in images_to_create.items():
        filepath = os.path.join(image_dir, filename)
        if not os.path.exists(filepath):
            img = Image.new('RGB', (200, 200), color=color)
            draw = ImageDraw.Draw(img)
            # ì¤‘ì•™ì— í…ìŠ¤íŠ¸ ì¶”ê°€ (í°íŠ¸ ë¯¸ì§€ì •ìœ¼ë¡œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
            draw.text((50, 90), text, fill=text_color)
            img.save(filepath)

# --- ë°ì´í„° ì €ì¥/ë¡œë“œ í•¨ìˆ˜ ---
RESULTS_FILE = "results.json"

def load_results():
    """JSON íŒŒì¼ì—ì„œ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    if os.path.exists(RESULTS_FILE):
        with open(RESULTS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"ì‚°ì„±": [], "ì—¼ê¸°ì„±": []}

def save_results(results):
    """ì‹¤í—˜ ê²°ê³¼ë¥¼ JSON íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤."""
    with open(RESULTS_FILE, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

# --- AI ëª¨ë¸ ì„¤ì • í•¨ìˆ˜ ---
def configure_ai():
    """API í‚¤ë¥¼ ì‚¬ìš©í•˜ì—¬ Gemini ëª¨ë¸ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            system_instruction="ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ê³¼í•™ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. ëª¨ë“  ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ì¡´ëŒ“ë§ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        )
        return model
    except Exception as e:
        # st.secretsì— í‚¤ê°€ ì—†ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš°
        return None

# --- 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ë° ì´ˆê¸°í™” ---
st.set_page_config(
    page_title="AI ì‚°-ì—¼ê¸° íƒêµ¬ ì‹¤í—˜ì‹¤",
    page_icon="ğŸ§ª",
    layout="wide"
)

# AI ëª¨ë¸ ì„¤ì •
ai_model = configure_ai()

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'current_experiment' not in st.session_state:
    st.session_state.current_experiment = None

# ì•± ì‹¤í–‰ ì‹œ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
create_images_if_needed()

# --- AIì˜ ì§€ì‹ ë°ì´í„° (ê°„ë‹¨í•œ ë”•ì…”ë„ˆë¦¬) ---
SOLUTION_DATA = {
    "ë ˆëª¬ì¦™": "ì‚°ì„±", "ì‹ì´ˆ": "ì‚°ì„±", "ì‚¬ì´ë‹¤": "ì‚°ì„±", "íƒ„ì‚°ìˆ˜": "ì‚°ì„±", "ì—¼ì‚°": "ì‚°ì„±",
    "ë¹„ëˆ—ë¬¼": "ì—¼ê¸°ì„±", "ì¹˜ì•½": "ì—¼ê¸°ì„±", "ìœ ë¦¬ì„¸ì •ì œ": "ì—¼ê¸°ì„±", "ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨": "ì—¼ê¸°ì„±", "ì„íšŒìˆ˜": "ì—¼ê¸°ì„±",
    "ë¬¼": "ì¤‘ì„±", "ì†Œê¸ˆë¬¼": "ì¤‘ì„±"
}

# --- 2. ì•± ì œëª© ë° ì„¤ëª… ---
st.title("ğŸ§ª AI ì‚°-ì—¼ê¸° íƒêµ¬ ì‹¤í—˜ì‹¤")
st.markdown("### ê¶ê¸ˆí•œ ìš©ì•¡ì„ AIì™€ í•¨ê»˜ íƒêµ¬í•´ë³´ê³  ì‚°ì„±ì¸ì§€ ì—¼ê¸°ì„±ì¸ì§€ ì•Œì•„ë´…ì‹œë‹¤!")

# --- 3. ê°€ìƒ ì‹¤í—˜ì‹¤ í™”ë©´ êµ¬ì„± ---
st.header("ğŸ”¬ í™œë™: ê°€ìƒ ì‹¤í—˜í•˜ê¸°")

# í™”ë©´ì„ ë‘ ê°œë¡œ ë¶„í•  (ì™¼ìª½: ì…ë ¥, ì˜¤ë¥¸ìª½: ê²°ê³¼)
st.markdown("---")
col1, col2 = st.columns([2, 1.5])

with col1:
    st.subheader("ğŸ“‹ ì‹¤í—˜ ì¤€ë¹„")
    
    # 1. ìš©ì•¡ ì´ë¦„ ì…ë ¥ë°›ê¸°
    solution_name = st.text_input(
        "ì–´ë–¤ ìš©ì•¡ì„ ì‹¤í—˜í•´ë³¼ê¹Œìš”?",
        placeholder="ì˜ˆ: ë ˆëª¬ì¦™, ë¹„ëˆ—ë¬¼, ì‚¬ì´ë‹¤"
    )

    # 2. ì§€ì‹œì•½ ì„ íƒí•˜ê¸°
    indicator = st.selectbox(
        "ì–´ë–¤ ì§€ì‹œì•½ì„ ì‚¬ìš©í•˜ê² ì–´ìš”?",
        ("ë¦¬íŠ¸ë¨¸ìŠ¤ ì¢…ì´", "í˜ë†€í”„íƒˆë ˆì¸ ìš©ì•¡")
    )

    # 3. ì‹¤í—˜ ì‹œì‘ ë²„íŠ¼
    start_button = st.button("ğŸ’§ ì‹¤í—˜ ì‹œì‘!")

with col2:
    st.subheader("ğŸ“Š ì‹¤í—˜ ê²°ê³¼")
    
    # 1. 'ì‹¤í—˜ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œì˜ ë¡œì§
    if start_button:
        if not solution_name:
            st.warning("ì–´ë–¤ ìš©ì•¡ìœ¼ë¡œ ì‹¤í—˜í• ì§€ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            with st.spinner(f"'{solution_name}' ìš©ì•¡ìœ¼ë¡œ ì‹¤í—˜ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."):
                time.sleep(1.5) # ì‹¤í—˜í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ê²Œ ì ì‹œ ëŒ€ê¸°
            
            # í˜„ì¬ ì‹¤í—˜ ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.current_experiment = {
                "name": solution_name,
                "indicator": indicator,
                "property": SOLUTION_DATA.get(solution_name, "ì•Œ ìˆ˜ ì—†ìŒ")
            }

    # 2. ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ì‹¤í—˜ ì •ë³´ê°€ ìˆìœ¼ë©´ ê²°ê³¼ í‘œì‹œ
    if st.session_state.current_experiment:
        exp = st.session_state.current_experiment
        prop = exp["property"]
        
        st.success(f"'{exp['name']}' ì‹¤í—˜ ì™„ë£Œ!")
        
        # ì§€ì‹œì•½ê³¼ ìš©ì•¡ ì„±ì§ˆì— ë”°ë¼ ê²°ê³¼ í‘œì‹œ
        if exp["indicator"] == "ë¦¬íŠ¸ë¨¸ìŠ¤ ì¢…ì´":
            if prop == "ì‚°ì„±": st.image("images/litmus_red.png", caption="í‘¸ë¥¸ìƒ‰ ë¦¬íŠ¸ë¨¸ìŠ¤ ì¢…ì´ê°€ ë¶‰ê²Œ ë³€í–ˆì–´ìš”!")
            elif prop == "ì—¼ê¸°ì„±": st.image("images/litmus_blue.png", caption="ë¶‰ì€ìƒ‰ ë¦¬íŠ¸ë¨¸ìŠ¤ ì¢…ì´ê°€ í‘¸ë¥´ê²Œ ë³€í–ˆì–´ìš”!")
            elif prop == "ì¤‘ì„±": st.info("ë¦¬íŠ¸ë¨¸ìŠ¤ ì¢…ì´ì˜ ìƒ‰ì´ ë³€í•˜ì§€ ì•Šì•˜ì–´ìš”.")
            else: st.error("ì²˜ìŒ ë³´ëŠ” ìš©ì•¡ì´ë¼ ê²°ê³¼ë¥¼ ì•Œ ìˆ˜ ì—†ì–´ìš”! ğŸ˜¥")
        
        elif exp["indicator"] == "í˜ë†€í”„íƒˆë ˆì¸ ìš©ì•¡":
            if prop in ["ì‚°ì„±", "ì¤‘ì„±"]: st.image("images/phenol_colorless.png", caption="í˜ë†€í”„íƒˆë ˆì¸ ìš©ì•¡ì˜ ìƒ‰ì´ ë³€í•˜ì§€ ì•Šì•˜ì–´ìš”.")
            elif prop == "ì—¼ê¸°ì„±": st.image("images/phenol_red.png", caption="í˜ë†€í”„íƒˆë ˆì¸ ìš©ì•¡ì´ ë¶‰ê²Œ ë³€í–ˆì–´ìš”!")
            else: st.error("ì²˜ìŒ ë³´ëŠ” ìš©ì•¡ì´ë¼ ê²°ê³¼ë¥¼ ì•Œ ìˆ˜ ì—†ì–´ìš”! ğŸ˜¥")

        # 3. í•™ìƒì˜ íŒë‹¨ ì…ë ¥ë°›ê¸°
        if prop != "ì•Œ ìˆ˜ ì—†ìŒ":
            st.markdown("---")
            st.subheader("ğŸ¤” ì´ ìš©ì•¡ì€ ë¬´ì—‡ì¼ê¹Œìš”?")
            
            student_choice = st.radio(
                "ì‹¤í—˜ ê²°ê³¼ë¥¼ ë³´ê³  ìš©ì•¡ì˜ ì„±ì§ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
                ("ì‚°ì„±", "ì—¼ê¸°ì„±", "ì¤‘ì„±"), 
                key=f"choice_{exp['name']}" # ìš©ì•¡ë§ˆë‹¤ ë‹¤ë¥¸ í‚¤ë¥¼ ë¶€ì—¬
            )
            
            if st.button("ê²°ê³¼ ê¸°ë¡í•˜ê¸°", key=f"submit_{exp['name']}"):
                if student_choice == prop:
                    st.success(f"ì •ë‹µì´ì—ìš”! '{exp['name']}'ì€(ëŠ”) '{prop}'ì´ ë§ì•„ìš”!")
                    st.balloons()
                    
                    # ê²°ê³¼ ì €ì¥
                    results = load_results()
                    if prop in results and exp['name'] not in results[prop]:
                        results[prop].append(exp['name'])
                        save_results(results)
                        st.info("ìš°ë¦¬ ë°˜ ì‹¤í—˜ ê²°ê³¼ì— ê¸°ë¡ë˜ì—ˆì–´ìš”!")

                else:
                    st.error(f"ì•„ì‰¬ì›Œìš”. ì´ ìš©ì•¡ì€ '{prop}'ì´ì—ìš”. ë‹¤ì‹œ í•œë²ˆ ìƒê°í•´ë³¼ê¹Œìš”?")
                
                # í˜„ì¬ ì‹¤í—˜ ì´ˆê¸°í™”
                st.session_state.current_experiment = None
                time.sleep(2)
                st.rerun() # í™”ë©´ ìƒˆë¡œê³ ì¹¨
    else:
        st.info("ì™¼ìª½ì—ì„œ ì‹¤í—˜í•  ìš©ì•¡ì„ ì…ë ¥í•˜ê³  'ì‹¤í—˜ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# --- 4. ìš°ë¦¬ ë°˜ ì „ì²´ ì‹¤í—˜ ê²°ê³¼ ---
st.markdown("---")
st.header("ğŸ“Š ìš°ë¦¬ ë°˜ ì „ì²´ ì‹¤í—˜ ê²°ê³¼")

results = load_results()

res_col1, res_col2 = st.columns(2)
with res_col1:
    st.subheader("ğŸ”´ ì‚°ì„± ìš©ì•¡")
    st.dataframe(results["ì‚°ì„±"], use_container_width=True)

with res_col2:
    st.subheader("ğŸ”µ ì—¼ê¸°ì„± ìš©ì•¡")
    st.dataframe(results["ì—¼ê¸°ì„±"], use_container_width=True)

# --- 5. AI ê³¼í•™ìì—ê²Œ ì§ˆë¬¸í•˜ê¸° ---
st.markdown("---")
st.header("ğŸ‘©â€ğŸ”¬ AI ê³¼í•™ìì—ê²Œ ì§ˆë¬¸í•˜ê¸°")

if ai_model:
    # ì´ì „ ëŒ€í™” ë‚´ìš© í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    if prompt := st.chat_input("ê³¼í•™ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”! (ì˜ˆ: ì™œ ë¹„ëˆ—ë¬¼ì€ ë¯¸ëŒê±°ë ¤ìš”?)"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° í‘œì‹œ
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        with st.chat_message("assistant"):
            with st.spinner("AI ê³¼í•™ì ì„ ìƒë‹˜ì´ ë‹µë³€ì„ ìƒê°í•˜ê³  ìˆì–´ìš”..."):
                response = ai_model.generate_content(prompt)
                response_text = response.text
                st.markdown(response_text)
        
        # AI ì‘ë‹µ ê¸°ë¡
        st.session_state.messages.append({"role": "assistant", "content": response_text})
else:
    st.warning("AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `.streamlit/secrets.toml` íŒŒì¼ì— API í‚¤ë¥¼ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")